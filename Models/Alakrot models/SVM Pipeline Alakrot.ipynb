{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  \n",
    "import numpy as np  \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0                               ORIGINAL_commentText  \\\n",
      "0           0  : O كاظم يسواكم بس انتم لان مقاماته تدرس فى ال...   \n",
      "1           1                                     : سخط على ليكي   \n",
      "2           2  ?  .  . مسائكم سعيد يا شباب , ممكن حد يقول لى ...   \n",
      "3           3  ؟  ؟  ؟  ؟  ؟  ؟  فهمونا بس هو انشهر بلبنان ول...   \n",
      "4           4   . \\nانا ضد تصرفات احلام بس ليه اسب واشتم وفى ...   \n",
      "\n",
      "                                         commentText Label  \n",
      "0  : O كاظم يسواكم بس انتم لان مقاماته تدرس فى ال...     N  \n",
      "1                                     : سخط على ليكي     P  \n",
      "2  ?  .  . مسائكم سعيد يا شباب , ممكن حد يقول لى ...     N  \n",
      "3  ؟  ؟  ؟  ؟  ؟  ؟  فهمونا بس هو انشهر بلبنان ول...     N  \n",
      "4   .  انا ضد تصرفات احلام بس ليه اسب واشتم وفى ا...     N  \n"
     ]
    }
   ],
   "source": [
    "# import the data\n",
    "data = pd.read_csv(\"clean_data_Alakrot.csv\")\n",
    "print (data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>commentText</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>الله يحسن حال العرب وبس 😊💔</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001</th>\n",
       "      <td>الله يحشرك مع بشار</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002</th>\n",
       "      <td>الله يحشرك مع بشار  .</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003</th>\n",
       "      <td>الله يحفظك يااستاذكاظم الحب ياروووعه ياظاغطهم ...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004</th>\n",
       "      <td>الله يحمى قيصر الغناء وهدا البقره  يلى بدو يدخ...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005</th>\n",
       "      <td>الله يحميك سوريا الاسد يا رب العالمين</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006</th>\n",
       "      <td>الله يحميك ويعطيكى طوله  العمر انتى واولاد الب...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007</th>\n",
       "      <td>الله يحميكى يا رغده  و يحمى بشار الاسد الى حمى...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008</th>\n",
       "      <td>الله يخارجنا كيف دى بيتحملها زوجها والله ودف م...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>الله يخارجنا منك يارب انت واخوكى الشاذ يا عبده...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            commentText Label\n",
       "2000                         الله يحسن حال العرب وبس 😊💔     N\n",
       "2001                                 الله يحشرك مع بشار     P\n",
       "2002                              الله يحشرك مع بشار  .     P\n",
       "2003  الله يحفظك يااستاذكاظم الحب ياروووعه ياظاغطهم ...     N\n",
       "2004  الله يحمى قيصر الغناء وهدا البقره  يلى بدو يدخ...     P\n",
       "2005              الله يحميك سوريا الاسد يا رب العالمين     N\n",
       "2006  الله يحميك ويعطيكى طوله  العمر انتى واولاد الب...     N\n",
       "2007  الله يحميكى يا رغده  و يحمى بشار الاسد الى حمى...     N\n",
       "2008  الله يخارجنا كيف دى بيتحملها زوجها والله ودف م...     P\n",
       "2009  الله يخارجنا منك يارب انت واخوكى الشاذ يا عبده...     P"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get needed columns:\n",
    "label_data = data[['commentText', 'Label']]\n",
    "label_data[2000:2010]\n",
    "# sample = label_data[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def clean_text(x):\n",
    "#     return str(x)\n",
    "\n",
    "# label_data[\"commentText\"] = label_data[\"commentText\"].apply(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the training model:\n",
    "from sklearn.model_selection import train_test_split\n",
    "# split data into (80% training and 20% testing):\n",
    "train, test = train_test_split(label_data, test_size=0.2)# sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "pipeline: ['tfidf', 'SVM']\n",
      "parameters:\n",
      "{'tfidf__use_idf': (True, False), 'tfidf__norm': ('l1', 'l2')}\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:   49.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 53.926s\n",
      "\n",
      "Best score: 0.788\n",
      "Best parameters set:\n",
      "\ttfidf__norm: 'l2'\n",
      "\ttfidf__use_idf: True\n",
      "accuracy= 0.7889581478183437\n",
      "recall= 0.7889581478183437\n",
      "precision= 0.7989479177577123\n",
      "weighted f-score 0.7833096208783122\n",
      "Confusion matrix\n",
      " [[1142  112]\n",
      " [ 362  630]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer # tf-idf feature to get the target words more accurate\n",
    "from sklearn.model_selection import GridSearchCV # grid search feature to enhance trianing\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB # no needed here\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC, LinearSVC # \"Support vector classifier\"\n",
    "model = SVC(kernel='linear', C=1E10)\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "# for evaluation\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score\n",
    "from time import time\n",
    "\n",
    "max_features = 5000 # to train the first 5000 instances as a standard for the whole corpus\n",
    "\n",
    "x = train['commentText']\n",
    "y = train['Label']\n",
    "\n",
    "\n",
    "tfidf = TfidfVectorizer(max_features=max_features)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', tfidf),\n",
    "    ('SVM', svm.SVC(kernel='linear')),\n",
    "])  # other parameters:\n",
    "    # svm.SVC(kernel='linear')\n",
    "    # SGDClassifier(loss='hinge', penalty='l2', alpha=1e-3, n_iter=5, random_state=42)\n",
    "    # SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0, decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf', max_iter=-1, probability=False, random_state=None, shrinking=True, tol=0.001, verbose=False)\n",
    "    # svm.SVC(kernel='rbf')\n",
    "    # For more information, visit: https://scikit-learn.org/stable/modules/svm.html.\n",
    "\n",
    "parameters = {\n",
    "    'tfidf__use_idf': (True, False),\n",
    "    'tfidf__norm': ('l1', 'l2')   \n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, parameters, cv=5,\n",
    "                               n_jobs=-1, verbose=1)\n",
    "\n",
    "print(\"Performing grid search...\")\n",
    "print(\"pipeline:\", [name for name, _ in pipeline.steps])\n",
    "print(\"parameters:\")\n",
    "print(parameters)\n",
    "t0 = time()\n",
    "grid_search.fit(x, y)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "print()\n",
    "\n",
    "print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = grid_search.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "    \n",
    "#refitting on entire training data using best settings\n",
    "grid_search.refit\n",
    "\n",
    "x_test = test['commentText']\n",
    "y_test = test['Label']\n",
    "\n",
    "predicted = grid_search.predict(x_test)\n",
    "print(\"accuracy=\", np.mean(predicted == y_test))\n",
    "print(\"recall=\", recall_score(y_test, predicted, average='weighted') )\n",
    "print(\"precision=\", precision_score(y_test, predicted, average='weighted'))\n",
    "print(\"weighted f-score\", f1_score(y_test, predicted, average='weighted'))\n",
    "print(\"Confusion matrix\\n\", confusion_matrix(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
