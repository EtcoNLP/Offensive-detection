{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  \n",
    "import numpy as np  \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set(font_scale=1.2)\n",
    "# Pickle package\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0                                               body  \\\n",
      "0           0  يبغى التنبيه على ان السعوديه  تستخدم صواريخ جو...   \n",
      "1           1  امريكا قتلت بالامس معوق رفض رفع يديه فماذا تري...   \n",
      "2           2  هذا الشخص هو من كان مؤيد لاحتلال العراق وضرب ا...   \n",
      "3           3  الى جمال ريان مذيع الجزيره  نحن من رعاك فى الم...   \n",
      "4           4  خيبه  الامل ليست تشاؤما ولا تقولا    ٠   عزم ل...   \n",
      "\n",
      "   languagecomment  \n",
      "0               -1  \n",
      "1               -1  \n",
      "2               -1  \n",
      "3               -1  \n",
      "4                0  \n"
     ]
    }
   ],
   "source": [
    "# import the data\n",
    "data = pd.read_csv(\"clean_data.csv\")\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot two ingredients\n",
    "# sns.lmplot('body', 'languagecomment', data=data, hue='Type',\n",
    "#            palette='Set1', fit_reg=False, scatter_kws={\"s\": 70});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>languagecomment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>يبغى التنبيه على ان السعوديه  تستخدم صواريخ جو...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>امريكا قتلت بالامس معوق رفض رفع يديه فماذا تري...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>هذا الشخص هو من كان مؤيد لاحتلال العراق وضرب ا...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>الى جمال ريان مذيع الجزيره  نحن من رعاك فى الم...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>خيبه  الامل ليست تشاؤما ولا تقولا    ٠   عزم ل...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>سفينه  الاكاذيب  والنفاق  والفاسد والاستبداد</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>لست ادرى  من هو الذى  ستنطفىء  شمعته وتتحرق  م...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>جمال خاشقجى اللبرالى العلمانى يتحول من داعيه ع...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>طرف ثالث محايد مثل من   ؟    الامم المتحده    ...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>عجيب   ,    لقد اصبحت تعريف كلمه  الارهاب بما ...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                body  languagecomment\n",
       "0  يبغى التنبيه على ان السعوديه  تستخدم صواريخ جو...               -1\n",
       "1  امريكا قتلت بالامس معوق رفض رفع يديه فماذا تري...               -1\n",
       "2  هذا الشخص هو من كان مؤيد لاحتلال العراق وضرب ا...               -1\n",
       "3  الى جمال ريان مذيع الجزيره  نحن من رعاك فى الم...               -1\n",
       "4  خيبه  الامل ليست تشاؤما ولا تقولا    ٠   عزم ل...                0\n",
       "5       سفينه  الاكاذيب  والنفاق  والفاسد والاستبداد               -1\n",
       "6  لست ادرى  من هو الذى  ستنطفىء  شمعته وتتحرق  م...               -1\n",
       "7  جمال خاشقجى اللبرالى العلمانى يتحول من داعيه ع...               -1\n",
       "8  طرف ثالث محايد مثل من   ؟    الامم المتحده    ...               -1\n",
       "9  عجيب   ,    لقد اصبحت تعريف كلمه  الارهاب بما ...               -1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_data = data[['body', 'languagecomment']]\n",
    "label_data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'algo'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-055dcabde55a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAdam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0malgo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCapsule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAttention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0malgo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrappers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDropConnect\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'algo'"
     ]
    }
   ],
   "source": [
    "import keras.backend as K\n",
    "from keras import Input, Model\n",
    "from keras.initializers import glorot_normal, orthogonal\n",
    "from keras.layers import Embedding, SpatialDropout1D, Bidirectional, GRU, Flatten, Dense, Dropout, BatchNormalization, \\\n",
    "    Reshape, Conv2D, MaxPool2D, Concatenate, GlobalAveragePooling1D, GlobalMaxPooling1D, concatenate, LSTM\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from algo.nn.layers import Capsule, Attention\n",
    "from algo.nn.wrappers import DropConnect\n",
    "\n",
    "\n",
    "def capsule(maxlen, max_features, embed_size, embedding_matrix):\n",
    "    K.clear_session()\n",
    "    inp = Input(shape=(maxlen,))\n",
    "    #     word = Embedding(max_features, embed_size, weights=[embedding_matrix], trainable=False)(inp)\n",
    "    #     emoji = Embedding(max_features, embed_size, weights=[emoji_embedding_matrix], trainable=False)(inp)\n",
    "    #     x = concatenate([(word), (emoji)])\n",
    "\n",
    "    x = Embedding(max_features, embed_size, weights=[embedding_matrix], trainable=False)(inp)\n",
    "\n",
    "    x = SpatialDropout1D(rate=0.2)(x)\n",
    "    #     x = Bidirectional(LSTM(64, return_sequences=True))(x)\n",
    "    x = Bidirectional(GRU(100, return_sequences=True,\n",
    "                          kernel_initializer=glorot_normal(seed=12300),\n",
    "                          recurrent_initializer=orthogonal(gain=1.0, seed=10000)))(x)\n",
    "\n",
    "    x = Capsule(num_capsule=10, dim_capsule=10, routings=4, share_weights=True)(x)\n",
    "    x = Flatten()(x)\n",
    "\n",
    "    x = Dense(100, activation=\"relu\", kernel_initializer=glorot_normal(seed=12300))(x)\n",
    "    x = Dropout(0.12)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = Dense(1, activation=\"sigmoid\")(x)\n",
    "    model = Model(inputs=inp, outputs=x)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def cnn_2d(maxlen, max_features, embed_size, embedding_matrix):\n",
    "    K.clear_session()\n",
    "\n",
    "    filter_sizes = [1, 2, 3, 5]\n",
    "    num_filters = 32\n",
    "\n",
    "    inp = Input(shape=(maxlen,))\n",
    "    x = Embedding(max_features, embed_size, weights=[embedding_matrix])(inp)\n",
    "    x = SpatialDropout1D(0.4)(x)\n",
    "    x = Reshape((maxlen, embed_size, 1))(x)\n",
    "\n",
    "    conv_0 = Conv2D(num_filters, kernel_size=(filter_sizes[0], embed_size), kernel_initializer='normal',\n",
    "                    activation='elu')(x)\n",
    "    conv_1 = Conv2D(num_filters, kernel_size=(filter_sizes[1], embed_size), kernel_initializer='normal',\n",
    "                    activation='elu')(x)\n",
    "    conv_2 = Conv2D(num_filters, kernel_size=(filter_sizes[2], embed_size), kernel_initializer='normal',\n",
    "                    activation='elu')(x)\n",
    "    conv_3 = Conv2D(num_filters, kernel_size=(filter_sizes[3], embed_size), kernel_initializer='normal',\n",
    "                    activation='elu')(x)\n",
    "\n",
    "    maxpool_0 = MaxPool2D(pool_size=(maxlen - filter_sizes[0] + 1, 1))(conv_0)\n",
    "    maxpool_1 = MaxPool2D(pool_size=(maxlen - filter_sizes[1] + 1, 1))(conv_1)\n",
    "    maxpool_2 = MaxPool2D(pool_size=(maxlen - filter_sizes[2] + 1, 1))(conv_2)\n",
    "    maxpool_3 = MaxPool2D(pool_size=(maxlen - filter_sizes[3] + 1, 1))(conv_3)\n",
    "\n",
    "    z = Concatenate(axis=1)([maxpool_0, maxpool_1, maxpool_2, maxpool_3])\n",
    "    z = Flatten()(z)\n",
    "    z = Dropout(0.1)(z)\n",
    "\n",
    "    outp = Dense(1, activation=\"sigmoid\")(z)\n",
    "\n",
    "    model = Model(inputs=inp, outputs=outp)\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def pooled_gru(maxlen, max_features, embed_size, embedding_matrix):\n",
    "    K.clear_session()\n",
    "    inp = Input(shape=(maxlen,))\n",
    "    x = Embedding(max_features, embed_size, weights=[embedding_matrix])(inp)\n",
    "    x = SpatialDropout1D(0.2)(x)\n",
    "    x = Bidirectional(GRU(80, return_sequences=True))(x)\n",
    "    avg_pool = GlobalAveragePooling1D()(x)\n",
    "    max_pool = GlobalMaxPooling1D()(x)\n",
    "    conc = concatenate([avg_pool, max_pool])\n",
    "    outp = Dense(1, activation=\"sigmoid\")(conc)\n",
    "\n",
    "    model = Model(inputs=inp, outputs=outp)\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "def lstm_attention(maxlen, max_features, embed_size, embedding_matrix):\n",
    "    K.clear_session()\n",
    "    inp = Input(shape=(maxlen,))\n",
    "    x = Embedding(max_features, embed_size, weights=[embedding_matrix], trainable=False)(inp)\n",
    "    x = Bidirectional(LSTM(64, return_sequences=True))(x)\n",
    "    x = Bidirectional(LSTM(64, return_sequences=True))(x)\n",
    "    x = Attention(maxlen)(x)\n",
    "    x = Dense(256, activation=\"relu\")(x)\n",
    "    # x = Dropout(0.25)(x)\n",
    "    x = Dense(1, activation=\"sigmoid\")(x)\n",
    "    model = Model(inputs=inp, outputs=x)\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def lstm_gru_attention(maxlen, max_features, embed_size, embedding_matrix):\n",
    "    inp = Input(shape=(maxlen,))\n",
    "    x = Embedding(max_features, embed_size, weights=[embedding_matrix], trainable=False)(inp)\n",
    "    x = SpatialDropout1D(0.1)(x)\n",
    "    x = Bidirectional(LSTM(40, return_sequences=True))(x)\n",
    "    y = Bidirectional(GRU(40, return_sequences=True))(x)\n",
    "\n",
    "    atten_1 = Attention(maxlen)(x)  # skip connect\n",
    "    atten_2 = Attention(maxlen)(y)\n",
    "    avg_pool = GlobalAveragePooling1D()(y)\n",
    "    max_pool = GlobalMaxPooling1D()(y)\n",
    "\n",
    "    conc = concatenate([atten_1, atten_2, avg_pool, max_pool])\n",
    "    conc = Dense(16, activation=\"relu\")(conc)\n",
    "    conc = Dropout(0.1)(conc)\n",
    "    outp = Dense(1, activation=\"sigmoid\")(conc)\n",
    "\n",
    "    model = Model(inputs=inp, outputs=outp)\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def attention_capsule(maxlen, max_features, embed_size, embedding_matrix):\n",
    "    inp = Input(shape=(maxlen,))\n",
    "    x = Embedding(max_features, embed_size, weights=[embedding_matrix], trainable=False)(inp)\n",
    "    x = SpatialDropout1D(rate=0.24)(x)\n",
    "    x = Bidirectional(LSTM(80,\n",
    "                           return_sequences=True,\n",
    "                           kernel_initializer=glorot_normal(seed=1029),\n",
    "                           recurrent_initializer=orthogonal(gain=1.0, seed=1029)))(x)\n",
    "\n",
    "    x_1 = Attention(maxlen)(x)\n",
    "    x_1 = DropConnect(Dense(32, activation=\"relu\"), prob=0.2)(x_1)\n",
    "\n",
    "    x_2 = Capsule(num_capsule=10, dim_capsule=10, routings=4, share_weights=True)(x)\n",
    "    x_2 = Flatten()(x_2)\n",
    "    x_2 = DropConnect(Dense(32, activation=\"relu\"), prob=0.2)(x_2)\n",
    "    conc = concatenate([x_1, x_2])\n",
    "    # conc = add([x_1, x_2])\n",
    "    outp = Dense(1, activation=\"sigmoid\")(conc)\n",
    "    model = Model(inputs=inp, outputs=outp)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from scipy import stats\n",
    "\n",
    "train, test = train_test_split(label_data, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-15-c5743c57d73d>, line 33)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-15-c5743c57d73d>\"\u001b[0;36m, line \u001b[0;32m33\u001b[0m\n\u001b[0;31m    parameters = {\u001b[0m\n\u001b[0m             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC, LinearSVC # \"Support vector classifier\"\n",
    "model = SVC(kernel='linear', C=1E10)\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score\n",
    "from time import time\n",
    "\n",
    "max_features = 5000\n",
    "\n",
    "x = train['body']\n",
    "y = train['languagecomment']\n",
    "\n",
    "\n",
    "tfidf = TfidfVectorizer(max_features=max_features)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', tfidf),\n",
    "    (LogisticRegression(verbose=1, solver='liblinear',random_state=0, C=5, penalty='l2',max_iter=1000)) # other parameters:\n",
    "    # SGDClassifier(loss='hinge', penalty='l2', alpha=1e-3, n_iter=5, random_state=42)\n",
    "    # svm.SVC(kernel='rbf')\n",
    "    # svm.SVC(kernel='linear')\n",
    "    \n",
    "parameters = {\n",
    "    'tfidf__use_idf': (True, False),\n",
    "    'tfidf__norm': ('l1', 'l2')   \n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, parameters, cv=5,\n",
    "                               n_jobs=-1, verbose=1)\n",
    "\n",
    "print(\"Performing grid search...\")\n",
    "print(\"pipeline:\", [name for name, _ in pipeline.steps])\n",
    "print(\"parameters:\")\n",
    "print(parameters)\n",
    "t0 = time()\n",
    "grid_search.fit(x, y)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "print()\n",
    "\n",
    "print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = grid_search.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "    \n",
    "#refitting on entire training data using best settings\n",
    "grid_search.refit\n",
    "\n",
    "x_test = test['body']\n",
    "y_test = test['languagecomment']\n",
    "\n",
    "predicted = grid_search.predict(x_test)\n",
    "print(\"accuracy=\", np.mean(predicted == y_test))\n",
    "print(\"recall=\", recall_score(y_test, predicted, average='weighted') )\n",
    "print(\"precision=\", precision_score(y_test, predicted, average='weighted'))\n",
    "print(\"weighted f-score\", f1_score(y_test, predicted, average='weighted'))\n",
    "print(\"Confusion matrix\\n\", confusion_matrix(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
